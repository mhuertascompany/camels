{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeaabe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import maps\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "plt.style.use(astropy_mpl_style)\n",
    "\n",
    "\n",
    "data_dir  = \"/net/diva/scratch-ssd1/mhuertas/users.flatironinstitute.org/~fvillaescusa/priv/DEPnzxoWlaTQ6CjrXqsm0vYi8L7Jy/CMD/2D_maps/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "604e90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "negloglik = lambda y, p_y: -p_y.log_prob(y)\n",
    "\n",
    "def build_model(nfilters, num_components, input_shape, output_shape):\n",
    "    cnn = tfk.Sequential([\n",
    "        tfkl.Conv2D(\n",
    "            nfilters, (4, 4),\n",
    "            input_shape=(input_shape, input_shape, 1),\n",
    "            padding=\"same\",\n",
    "            activation='relu'),\n",
    "        tfkl.BatchNormalization(),\n",
    "        tfkl.MaxPool2D((2, 2), strides=2),\n",
    "        tfkl.Conv2D(\n",
    "            nfilters * 2, (3, 3),\n",
    "            padding=\"same\",\n",
    "            activation='relu'),\n",
    "        tfkl.MaxPool2D((2, 2), strides=2),\n",
    "        tfkl.Conv2D(\n",
    "            nfilters * 4, (2, 2),\n",
    "            padding=\"same\",\n",
    "            activation='relu'),\n",
    "        tfkl.MaxPool2D((2, 2), strides=2),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tfkl.Dense(128, activation='relu'),\n",
    "        tfkl.Droput(0.5),\n",
    "        tfkl.Dense(64, activation='relu'),\n",
    "        tfkl.Droput(0.5),\n",
    "        tfkl.Dense(64, activation='tanh'),\n",
    "        tfkl.Dense(tfpl.MixtureNormal.params_size(num_components), activation=None),\n",
    "        tfpl.MixtureNormal(num_components)\n",
    "    ])\n",
    "\n",
    "    cnn.compile(optimizer=tf.optimizers.Adam(learning_rate=0.00002), loss=negloglik)\n",
    "\n",
    "    return cnn\n",
    "\n",
    "def preprocessing(example):\n",
    "#     def conv(x):\n",
    "    #example['flux'] = to_mag(example['flux'])\n",
    "    #example['flux'] = example['flux']/46.\n",
    "    #example = example[np.where(example['mass']>0.5)]\n",
    "    return example['Mgas'], example['omega_m']\n",
    "\n",
    "def input_fn(mode='train', batch_size=64):\n",
    "    \"\"\"\n",
    "    mode: 'train' or 'test' or 'val'\n",
    "    \"\"\"\n",
    "    if mode == 'train':\n",
    "        dataset = tfds.load('maps', split='train[:80%]',data_dir=data_dir)\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(10000)\n",
    "        \n",
    "    elif mode == 'val':\n",
    "        dataset = tfds.load('maps', split='train[80%:90%]',data_dir=data_dir)\n",
    "    else:\n",
    "        dataset = tfds.load('maps', split='train[90%:]',data_dir=data_dir)\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    #dataset = dataset.map(lambda ex: ex['Mgas'], ex['omega_m'])\n",
    "    dataset = dataset.map(preprocessing) # Apply data preprocessing\n",
    "    dataset = dataset.prefetch(-1)  # fetch next batches while training current one (-1 for autotune)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86e20b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "234/234 [==============================] - 17s 60ms/step - loss: -0.2246 - val_loss: -0.5470\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 14s 59ms/step - loss: -0.7692 - val_loss: -0.6186\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 14s 59ms/step - loss: -0.9514 - val_loss: -0.5657\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 14s 59ms/step - loss: -1.0897 - val_loss: -0.4231\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 14s 59ms/step - loss: -1.2380 - val_loss: -0.0080\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - 14s 59ms/step - loss: -1.3496 - val_loss: 0.0076\n",
      "Epoch 7/20\n",
      "234/234 [==============================] - 14s 60ms/step - loss: -1.4709 - val_loss: 0.3470\n",
      "Epoch 8/20\n",
      "234/234 [==============================] - 14s 60ms/step - loss: -1.5743 - val_loss: 0.6462\n",
      "Epoch 9/20\n",
      "234/234 [==============================] - 14s 59ms/step - loss: -1.6721 - val_loss: 1.3492\n",
      "Epoch 10/20\n",
      "234/234 [==============================] - 14s 60ms/step - loss: -1.7577 - val_loss: 1.6393\n",
      "Epoch 11/20\n",
      "234/234 [==============================] - 14s 59ms/step - loss: -1.8391 - val_loss: 2.1657\n",
      "Epoch 12/20\n",
      "234/234 [==============================] - 14s 59ms/step - loss: -1.9108 - val_loss: 2.8668\n",
      "Epoch 13/20\n",
      "234/234 [==============================] - 14s 60ms/step - loss: -1.9894 - val_loss: 3.5265\n",
      "Epoch 14/20\n",
      "234/234 [==============================] - 14s 60ms/step - loss: -2.0426 - val_loss: 4.3626\n",
      "Epoch 15/20\n",
      "234/234 [==============================] - 14s 60ms/step - loss: -2.0707 - val_loss: 4.0660\n",
      "Epoch 16/20\n",
      "234/234 [==============================] - 14s 60ms/step - loss: -2.1611 - val_loss: 5.7361\n",
      "Epoch 17/20\n",
      "234/234 [==============================] - 14s 59ms/step - loss: -2.1837 - val_loss: 5.6681\n",
      "Epoch 18/20\n",
      "234/234 [==============================] - 14s 60ms/step - loss: -2.2317 - val_loss: 6.4117\n",
      "Epoch 19/20\n",
      "234/234 [==============================] - 14s 60ms/step - loss: -2.2777 - val_loss: 7.4654\n",
      "Epoch 20/20\n",
      "234/234 [==============================] - 14s 59ms/step - loss: -2.3265 - val_loss: 7.5951\n"
     ]
    }
   ],
   "source": [
    "dset = input_fn()\n",
    "dval = input_fn(mode='val')\n",
    "cnn = build_model(16,1,256,1)\n",
    "history = cnn.fit(dset, epochs=20,steps_per_epoch=234,validation_data=dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c22dbc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
